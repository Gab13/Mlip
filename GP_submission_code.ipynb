{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import sklearn.gaussian_process.kernels as K\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 280\n",
    "h = 28\n",
    "start = 1969 - h - n\n",
    "end = 1969"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_last = 1913\n",
    "max_lags = 57 \n",
    "start_day = 350\n",
    "\n",
    "numcols = [str(day) for day in range(start_day,tr_last+1)]\n",
    "\n",
    "dtype = {numcol:\"float32\" for numcol in numcols} \n",
    "\n",
    "train = pd.read_csv(\"m5-forecasting-accuracy/sales_train_evaluation.csv\", dtype = dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = train.loc[:, 'id'].to_frame()\n",
    "#print(ids.shape)\n",
    "\n",
    "useless_slice = train.loc[:, 'd_1914':'d_1941']\n",
    "#print(useless_slice.shape)\n",
    "\n",
    "df = pd.concat([ids, useless_slice], axis = 1)\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calendar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"weekday\": \"category\", \n",
    "            'wm_yr_wk': 'int16', \n",
    "            \"wday\": \"int16\",\n",
    "            \"month\": \"int16\", \n",
    "            \"year\": \"int16\", \n",
    "            \"event_name_1\": \"category\", \n",
    "            \"event_name_2\": \"category\", \n",
    "            \"event_type_1\": \"category\", \n",
    "            \"event_type_2\": \"category\", \n",
    "            \"snap_CA\": \"float32\", \n",
    "            'snap_TX': 'float32', \n",
    "            'snap_WI': 'float32'}\n",
    "\n",
    "calendar = pd.read_csv(\"m5-forecasting-accuracy/calendar.csv\", dtype = CAL_DTYPES)\n",
    "\n",
    "calendar[\"date\"] = pd.to_datetime(calendar[\"date\"]) # this changes the format of the 'date' column to handier one\n",
    "\n",
    "for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            calendar[col] = calendar[col].cat.codes.astype(\"int16\") # changes category to int16! so now Boolean\n",
    "            calendar[col] -= calendar[col].min() # this changes the -1 values in the event_name and _type columns to 0\n",
    "\n",
    "\n",
    "events = calendar.loc[:, 'event_name_1':'event_type_2'][start:end].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_CA = [ [x] for x in calendar.loc[:, 'snap_CA'][start:end].tolist()]\n",
    "snap_TX = [ [x] for x in calendar.loc[:, 'snap_TX'][start:end].tolist()]\n",
    "snap_WI = [ [x] for x in calendar.loc[:, 'snap_WI'][start:end].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(snap_CA))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second 30490 rows of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = train.loc[:, 'd_1662':'d_1941']\n",
    "ids = train.loc[:, 'id']\n",
    "store_ids = train.loc[:, 'store_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = K.RBF() + K.ExpSineSquared() * K.RationalQuadratic() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = []\n",
    "\n",
    "for i in range(11):\n",
    "    t1 = time.time()\n",
    "    \n",
    "    x = [ [i] for i in range(start, end)]\n",
    "    x = [x + y for x, y in zip(x, events)]\n",
    "    store_id = store_ids.loc[0]\n",
    "\n",
    "    if store_id in ['CA_1', 'CA_2', 'CA_3', 'CA_4']:\n",
    "        x = [x + y for x, y in zip(x, snap_CA)]\n",
    "    elif store_id in ['TX_1', 'TX_2', 'TX_3']:\n",
    "        x = [x + y for x, y in zip(x, snap_TX)]\n",
    "    elif store_id in ['WI_1', 'WI_2', 'WI_3']:\n",
    "        x = [x + y for x, y in zip(x, snap_WI)]\n",
    "    \n",
    "    X = x[:280]\n",
    "    \n",
    "    Y = training_data.loc[i, :].tolist()\n",
    "    \n",
    "    \n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "\n",
    "    gp.fit(X, Y)\n",
    "\n",
    "    Y_pred = gp.predict(x, return_std=False)\n",
    "    \n",
    "    predictions = Y_pred[280:]\n",
    "    row = [ids[i]] + predictions.tolist()\n",
    "\n",
    "    matrix.append(row)\n",
    "    t2 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 29)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame = pd.DataFrame(matrix, columns = [\"id\"] + [\"F\" + str(i) for i in range (1, 29)])\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing dataframe to .xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30490, 29)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "\n",
    "columns = [\"id\"] + [\"F\" + str(i) for i in range (1, 29)]\n",
    "df.columns = columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30501, 29)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, frame])\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is written successfully to Excel File.\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter('output.xlsx')\n",
    "df.to_excel(writer, index = False)\n",
    "writer.save()\n",
    "\n",
    "print('DataFrame is written successfully to Excel File.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
